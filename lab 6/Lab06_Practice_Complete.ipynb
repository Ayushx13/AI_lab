{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the Classification using Bayes Classifier and Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the dataset and prepare the train, validation, and test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df = pd.read_csv('Date_Fruit_Datasets.csv')\n",
    "\n",
    "# Display first few rows of train data\n",
    "print(df.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "print(\"\\nFeatures (X) shape:\", X.shape)\n",
    "print(\"Target  (y) shape:\", y.shape)\n",
    "print(\"\\nNumber of features:\", X.shape[1])\n",
    "print(\"Number of classes :\", y.nunique())\n",
    "print(\"Classes           :\", sorted(y.unique()))\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# First split  →  60% Train  |  40% Temp (Validation + Test)\n",
    "# --------------------------------------------------------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.4,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Second split  →  Temp split equally into 20% Validation | 20% Test\n",
    "# --------------------------------------------------------------------------\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Print sizes\n",
    "print(\"\\nSplit Summary:\")\n",
    "print(f\"  Training set  : {X_train.shape[0]} samples  ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Validation set: {X_val.shape[0]} samples  ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test set      : {X_test.shape[0]} samples  ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nClass distribution per split:\")\n",
    "print(f\"  Train :  {y_train.value_counts().sort_index().tolist()}\")\n",
    "print(f\"  Val   :  {y_val.value_counts().sort_index().tolist()}\")\n",
    "print(f\"  Test  :  {y_test.value_counts().sort_index().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes classifier implementation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compute mean and covariance matrix of each class\n",
    "### 2. Computer Prior probability of each class\n",
    "### 3. For each test example/sample and for each class, calculate likelihood, prior probability, total probability, and then posterior probability\n",
    "### 4. Now, for each test sample, we have c number of posterior probability. Here, c is the number of classes/targets. Find for which class, posterior probability is maximum and assign this class label to the test sample.\n",
    "### 5. Get the prediction label for each test sample and evaluate the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for Bayes Classifier\n",
    "\n",
    "# Get unique classes\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Create dictionaries to store parameters for each class\n",
    "class_means = {}\n",
    "class_covs = {}\n",
    "class_priors = {}\n",
    "\n",
    "# Step 1 & 2: Compute mean, covariance matrix, and prior probability for each class\n",
    "print(\"Training Bayes Classifier...\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"PARAMETER ESTIMATION FOR EACH CLASS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for cls in classes:\n",
    "    # Get samples belonging to this class\n",
    "    X_class = X_train[y_train == cls]\n",
    "    \n",
    "    # Compute mean vector (μ_i)\n",
    "    class_means[cls] = np.mean(X_class, axis=0)\n",
    "    \n",
    "    # Compute covariance matrix (Σ_i)\n",
    "    class_covs[cls] = np.cov(X_class, rowvar=False)\n",
    "    \n",
    "    # Compute prior probability P(C_i)\n",
    "    class_priors[cls] = len(X_class) / len(X_train)\n",
    "    \n",
    "    print(f\"\\nClass: {cls}\")\n",
    "    print(f\"  Number of samples: {len(X_class)}\")\n",
    "    print(f\"  Prior probability: {class_priors[cls]:.4f}\")\n",
    "    print(f\"  Mean vector shape: {class_means[cls].shape}\")\n",
    "    print(f\"  Covariance matrix shape: {class_covs[cls].shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training completed!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict using Bayes Classifier\n",
    "def bayes_predict(X_data, class_means, class_covs, class_priors, classes):\n",
    "    \"\"\"\n",
    "    Predict class labels using Bayes classifier\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_data : array-like\n",
    "        Input features\n",
    "    class_means : dict\n",
    "        Mean vectors for each class\n",
    "    class_covs : dict\n",
    "        Covariance matrices for each class\n",
    "    class_priors : dict\n",
    "        Prior probabilities for each class\n",
    "    classes : array-like\n",
    "        List of class labels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : array\n",
    "        Predicted class labels\n",
    "    \"\"\"\n",
    "    n_samples = len(X_data)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # Initialize array to store posterior probabilities\n",
    "    # Shape: (n_samples, n_classes)\n",
    "    posteriors = np.zeros((n_samples, n_classes))\n",
    "    \n",
    "    # Step 3: Calculate likelihood and posterior for each class\n",
    "    for idx, cls in enumerate(classes):\n",
    "        # Calculate likelihood p(x|μ_i, Σ_i) for all samples at once\n",
    "        likelihood = multivariate_normal.pdf(\n",
    "            np.array(X_data),\n",
    "            mean=class_means[cls],\n",
    "            cov=class_covs[cls],\n",
    "            allow_singular=True\n",
    "        )\n",
    "        \n",
    "        # Calculate numerator: likelihood * prior\n",
    "        posteriors[:, idx] = likelihood * class_priors[cls]\n",
    "    \n",
    "    # Calculate total probability (denominator) for normalization\n",
    "    total_probabilities = np.sum(posteriors, axis=1, keepdims=True)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    total_probabilities[total_probabilities == 0] = 1e-10\n",
    "    \n",
    "    # Calculate normalized posterior probabilities\n",
    "    posteriors = posteriors / total_probabilities\n",
    "    \n",
    "    # Step 4: Assign class with maximum posterior probability\n",
    "    predictions_idx = np.argmax(posteriors, axis=1)\n",
    "    predictions = classes[predictions_idx]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Predict on validation data\n",
    "print(\"\\nPredicting on Validation Data...\")\n",
    "y_val_pred_bayes = bayes_predict(X_val, class_means, class_covs, class_priors, classes)\n",
    "print(f\"Validation predictions shape: {y_val_pred_bayes.shape}\")\n",
    "\n",
    "# Predict on test data\n",
    "print(\"\\nPredicting on Test Data...\")\n",
    "y_test_pred_bayes = bayes_predict(X_test, class_means, class_covs, class_priors, classes)\n",
    "print(f\"Test predictions shape: {y_test_pred_bayes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics evaluation for Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find confusion matrix, accuracy, precision, recall, and f1-score for validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for performance metrics evaluation\n",
    "\n",
    "def evaluate_performance(y_true, y_pred, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Evaluate and print performance metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "    dataset_name : str\n",
    "        Name of the dataset (for printing)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"PERFORMANCE METRICS - {dataset_name}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Precision (macro and micro)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro')\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    print(f\"\\nPrecision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    \n",
    "    # Recall (macro and micro)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    print(f\"\\nRecall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    \n",
    "    # F1-Score (macro and micro)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "    print(f\"\\nF1-Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'confusion_matrix': cm,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro\n",
    "    }\n",
    "\n",
    "# Evaluate Bayes Classifier on Validation Data\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"# BAYES CLASSIFIER EVALUATION\")\n",
    "print(\"#\"*70)\n",
    "val_metrics_bayes = evaluate_performance(y_val, y_val_pred_bayes, \"Validation Set (Bayes Classifier)\")\n",
    "\n",
    "# Evaluate Bayes Classifier on Test Data\n",
    "test_metrics_bayes = evaluate_performance(y_test, y_test_pred_bayes, \"Test Set (Bayes Classifier)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier (Using GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING NAIVE BAYES CLASSIFIER (GaussianNB)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nNaive Bayes model trained successfully!\")\n",
    "print(f\"Number of classes: {len(nb.classes_)}\")\n",
    "print(f\"Classes: {nb.classes_}\")\n",
    "\n",
    "# Predicted Labels for Validation Data\n",
    "y_val_pred_nb = nb.predict(X_val)\n",
    "print(f\"\\nValidation predictions shape: {y_val_pred_nb.shape}\")\n",
    "\n",
    "# Predicted Labels for Test Data\n",
    "y_test_pred_nb = nb.predict(X_test)\n",
    "print(f\"Test predictions shape: {y_test_pred_nb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics evaluation for Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find confusion matrix, accuracy, precision, recall, and f1-score for validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for performance metrics evaluation\n",
    "\n",
    "# Evaluate Naive Bayes Classifier on Validation Data\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"# NAIVE BAYES CLASSIFIER EVALUATION\")\n",
    "print(\"#\"*70)\n",
    "val_metrics_nb = evaluate_performance(y_val, y_val_pred_nb, \"Validation Set (Naive Bayes Classifier)\")\n",
    "\n",
    "# Evaluate Naive Bayes Classifier on Test Data\n",
    "test_metrics_nb = evaluate_performance(y_test, y_test_pred_nb, \"Test Set (Naive Bayes Classifier)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Bayes and Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance of both classifiers\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: BAYES vs NAIVE BAYES CLASSIFIERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision (Macro)', 'Precision (Micro)', \n",
    "               'Recall (Macro)', 'Recall (Micro)', 'F1-Score (Macro)', 'F1-Score (Micro)'],\n",
    "    'Bayes (Val)': [\n",
    "        val_metrics_bayes['accuracy'],\n",
    "        val_metrics_bayes['precision_macro'],\n",
    "        val_metrics_bayes['precision_micro'],\n",
    "        val_metrics_bayes['recall_macro'],\n",
    "        val_metrics_bayes['recall_micro'],\n",
    "        val_metrics_bayes['f1_macro'],\n",
    "        val_metrics_bayes['f1_micro']\n",
    "    ],\n",
    "    'Bayes (Test)': [\n",
    "        test_metrics_bayes['accuracy'],\n",
    "        test_metrics_bayes['precision_macro'],\n",
    "        test_metrics_bayes['precision_micro'],\n",
    "        test_metrics_bayes['recall_macro'],\n",
    "        test_metrics_bayes['recall_micro'],\n",
    "        test_metrics_bayes['f1_macro'],\n",
    "        test_metrics_bayes['f1_micro']\n",
    "    ],\n",
    "    'Naive Bayes (Val)': [\n",
    "        val_metrics_nb['accuracy'],\n",
    "        val_metrics_nb['precision_macro'],\n",
    "        val_metrics_nb['precision_micro'],\n",
    "        val_metrics_nb['recall_macro'],\n",
    "        val_metrics_nb['recall_micro'],\n",
    "        val_metrics_nb['f1_macro'],\n",
    "        val_metrics_nb['f1_micro']\n",
    "    ],\n",
    "    'Naive Bayes (Test)': [\n",
    "        test_metrics_nb['accuracy'],\n",
    "        test_metrics_nb['precision_macro'],\n",
    "        test_metrics_nb['precision_micro'],\n",
    "        test_metrics_nb['recall_macro'],\n",
    "        test_metrics_nb['recall_micro'],\n",
    "        test_metrics_nb['f1_macro'],\n",
    "        test_metrics_nb['f1_micro']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nSUMMARY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Bayes Classifier Test Accuracy: {test_metrics_bayes['accuracy']:.4f}\")\n",
    "print(f\"Naive Bayes Classifier Test Accuracy: {test_metrics_nb['accuracy']:.4f}\")\n",
    "print(\"\\nKey Difference:\")\n",
    "print(\"- Bayes Classifier: Uses full covariance matrix (captures feature dependencies)\")\n",
    "print(\"- Naive Bayes Classifier: Assumes feature independence (diagonal covariance)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
