{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Lab 07 Practice: Logistic Regression and Support Vector Machines\n",
    "**CS201L: Artificial Intelligence Laboratory**  \n",
    "**Indian Institute of Technology, Dharwad**\n",
    "\n",
    "---\n",
    "\n",
    "In this lab we will:\n",
    "1. Load and preprocess the **Date Fruit** dataset\n",
    "2. Train a **Logistic Regression** model and analyze feature weights\n",
    "3. Train **SVM** models with Linear, Polynomial, and RBF kernels\n",
    "4. Tune the hyperparameter **C** using the validation set\n",
    "5. Evaluate all models using standard classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset\n",
    "\n",
    "The dataset is already split into Train (60%), Validation (20%), and Test (20%) sets.  \n",
    "We load each CSV separately and separate the features from the target label (`Class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train, validation and test splits\n",
    "X_train_df = pd.read_csv(\"DateFruit_Train.csv\")\n",
    "X_val_df   = pd.read_csv(\"DateFruit_Validation.csv\")\n",
    "X_test_df  = pd.read_csv(\"DateFruit_Test.csv\")\n",
    "\n",
    "# Separating features and labels\n",
    "# 'Class' is the target column, rest are features\n",
    "X_train = X_train_df.drop(columns=[\"Class\"])\n",
    "y_train = X_train_df[\"Class\"]\n",
    "\n",
    "X_val   = X_val_df.drop(columns=[\"Class\"])\n",
    "y_val   = X_val_df[\"Class\"]\n",
    "\n",
    "X_test  = X_test_df.drop(columns=[\"Class\"])\n",
    "y_test  = X_test_df[\"Class\"]\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Train size     : {X_train.shape}\")\n",
    "print(f\"Validation size: {X_val.shape}\")\n",
    "print(f\"Test size      : {X_test.shape}\")\n",
    "print(f\"\\nClasses: {y_train.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a quick look at the training data\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "## Step 2: Data Scaling\n",
    "\n",
    "**Why is scaling important?**  \n",
    "This dataset has 34 features with very different value ranges. If we don't scale, features with larger values will dominate the model and make training unstable (especially for SVM and Logistic Regression).\n",
    "\n",
    "`StandardScaler` transforms each feature to have **zero mean** and **unit variance**.\n",
    "\n",
    "> **Important:** We `fit` the scaler **only on training data** and then `transform` val/test with the same scaler. Fitting on val/test would be data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit ONLY on training data, then transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Only transform val and test (DO NOT fit again!)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data scaling done using StandardScaler.\")\n",
    "print(f\"Mean of first feature in train (should be ~0): {X_train_scaled[:, 0].mean():.4f}\")\n",
    "print(f\"Std  of first feature in train (should be ~1): {X_train_scaled[:, 0].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## Step 3: Helper Function for Metrics\n",
    "\n",
    "We'll be evaluating many models, so let's write a helper function once to avoid repeating the same code every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, dataset_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Prints confusion matrix and classification metrics\n",
    "    for multiclass classification.\n",
    "    \"\"\"\n",
    "    cm       = confusion_matrix(y_true, y_pred)\n",
    "    acc      = accuracy_score(y_true, y_pred)\n",
    "    prec_mac = precision_score(y_true, y_pred, average='macro',  zero_division=0)\n",
    "    prec_mic = precision_score(y_true, y_pred, average='micro',  zero_division=0)\n",
    "    rec_mac  = recall_score(y_true, y_pred,    average='macro',  zero_division=0)\n",
    "    rec_mic  = recall_score(y_true, y_pred,    average='micro',  zero_division=0)\n",
    "    f1_mac   = f1_score(y_true, y_pred,        average='macro',  zero_division=0)\n",
    "    f1_mic   = f1_score(y_true, y_pred,        average='micro',  zero_division=0)\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"  {dataset_name} Results\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"\\nAccuracy          : {acc:.4f}\")\n",
    "    print(f\"Precision (Macro) : {prec_mac:.4f}\")\n",
    "    print(f\"Precision (Micro) : {prec_mic:.4f}\")\n",
    "    print(f\"Recall    (Macro) : {rec_mac:.4f}\")\n",
    "    print(f\"Recall    (Micro) : {rec_mic:.4f}\")\n",
    "    print(f\"F1-Score  (Macro) : {f1_mac:.4f}\")\n",
    "    print(f\"F1-Score  (Micro) : {f1_mic:.4f}\")\n",
    "\n",
    "    return acc\n",
    "\n",
    "print(\"Helper function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Logistic Regression\n",
    "\n",
    "Logistic Regression fits a linear model to the log-odds and uses the sigmoid function to output class probabilities. For multiclass (like our date fruit dataset), sklearn uses One-vs-Rest (OvR) by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing and training the Logistic Regression model\n",
    "# max_iter=1000 because the default 100 might not be enough to converge\n",
    "logistic_reg = LogisticRegression(max_iter=1000)\n",
    "logistic_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Logistic Regression model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on validation and test data\n",
    "y_val_pred_lr  = logistic_reg.predict(X_val_scaled)\n",
    "y_test_pred_lr = logistic_reg.predict(X_test_scaled)\n",
    "\n",
    "# Printing metrics for both splits\n",
    "print_metrics(y_val,  y_val_pred_lr,  dataset_name=\"Logistic Regression - Validation\")\n",
    "print_metrics(y_test, y_test_pred_lr, dataset_name=\"Logistic Regression - Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "### Task 1 – Feature Importance via Weight Vector\n",
    "\n",
    "For multiclass Logistic Regression, `coef_` has shape `(n_classes, n_features)`.  \n",
    "We take the **mean of absolute values** across classes to get one importance score per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the weight vector\n",
    "weights = logistic_reg.coef_\n",
    "print(f\"Shape of coef_ : {weights.shape}  (n_classes x n_features)\")\n",
    "\n",
    "# Taking mean of absolute values across all classes\n",
    "avg_weights   = np.mean(np.abs(weights), axis=0)\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Plotting bar graph of feature weights\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(range(len(avg_weights)), avg_weights, color='steelblue')\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=90, fontsize=7)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Mean |Weight|\")\n",
    "plt.title(\"Logistic Regression – Feature Importance (Mean Absolute Weights)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lr_feature_importance.png\", dpi=150)\n",
    "plt.show()\n",
    "print(\"Plot saved as 'lr_feature_importance.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Support Vector Machine (SVM)\n",
    "\n",
    "SVM tries to find the **optimal hyperplane** that separates classes with the **maximum margin**. We will experiment with three types of kernels:\n",
    "- **Linear** – for linearly separable data\n",
    "- **Polynomial** – captures non-linear interactions (degrees 2, 3, 4, 5)\n",
    "- **RBF** – great general-purpose non-linear kernel\n",
    "\n",
    "We tune the regularization parameter **C** using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C values to try for hyperparameter tuning\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# We'll store all results here to make a comparison table at the end\n",
    "results_table = []\n",
    "\n",
    "print(\"C values to try:\", C_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "### Task 2a: SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM with Linear Kernel – Tuning C\\n\")\n",
    "print(f\"{'C':<10} {'Val Accuracy':<18} {'Test Accuracy'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "best_val_acc_linear = 0\n",
    "best_C_linear       = None\n",
    "best_linear_model   = None\n",
    "\n",
    "for C in C_values:\n",
    "    svm_linear = SVC(kernel='linear', C=C)\n",
    "    svm_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_val_pred  = svm_linear.predict(X_val_scaled)\n",
    "    y_test_pred = svm_linear.predict(X_test_scaled)\n",
    "\n",
    "    val_acc  = accuracy_score(y_val,  y_val_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"{C:<10} {val_acc:<18.4f} {test_acc:.4f}\")\n",
    "    results_table.append({\"Kernel\": \"Linear\", \"C\": C, \"Degree\": \"-\",\n",
    "                           \"Val Acc\": round(val_acc, 4), \"Test Acc\": round(test_acc, 4)})\n",
    "\n",
    "    # Track the best model based on validation accuracy\n",
    "    if val_acc > best_val_acc_linear:\n",
    "        best_val_acc_linear = val_acc\n",
    "        best_C_linear       = C\n",
    "        best_linear_model   = svm_linear\n",
    "\n",
    "print(f\"\\n>> Best C for Linear SVM: {best_C_linear}  (Val Accuracy: {best_val_acc_linear:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed metrics for the best linear SVM\n",
    "y_val_pred_best  = best_linear_model.predict(X_val_scaled)\n",
    "y_test_pred_best = best_linear_model.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(y_val,  y_val_pred_best,  dataset_name=f\"Linear SVM (C={best_C_linear}) – Validation\")\n",
    "print_metrics(y_test, y_test_pred_best, dataset_name=f\"Linear SVM (C={best_C_linear}) – Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight plot for Linear SVM\n",
    "# coef_ is available only for the linear kernel\n",
    "# Shape: (n_classes*(n_classes-1)/2, n_features) for OvO multi-class\n",
    "lin_weights     = best_linear_model.coef_\n",
    "avg_lin_weights = np.mean(np.abs(lin_weights), axis=0)\n",
    "\n",
    "print(f\"Shape of coef_ for Linear SVM: {lin_weights.shape}\")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(range(len(avg_lin_weights)), avg_lin_weights, color='darkorange')\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=90, fontsize=7)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Mean |Weight|\")\n",
    "plt.title(f\"Linear SVM (C={best_C_linear}) – Feature Weights\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"svm_linear_weights.png\", dpi=150)\n",
    "plt.show()\n",
    "print(\"Plot saved as 'svm_linear_weights.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "### Task 2b: SVM with Polynomial Kernel\n",
    "\n",
    "Polynomial kernel: $K(x_i, x_j) = (\\gamma \\cdot x_i^T x_j + r)^d$\n",
    "\n",
    "We try degrees [2, 3, 4, 5] and all C values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM with Polynomial Kernel – Tuning C and Degree\\n\")\n",
    "degrees = [2, 3, 4, 5]\n",
    "print(f\"{'C':<10} {'Degree':<10} {'Val Accuracy':<18} {'Test Accuracy'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for degree in degrees:\n",
    "    for C in C_values:\n",
    "        poly_svm = SVC(kernel='poly', degree=degree, C=C, gamma='scale')\n",
    "        poly_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_val_pred  = poly_svm.predict(X_val_scaled)\n",
    "        y_test_pred = poly_svm.predict(X_test_scaled)\n",
    "\n",
    "        val_acc  = accuracy_score(y_val,  y_val_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        print(f\"{C:<10} {degree:<10} {val_acc:<18.4f} {test_acc:.4f}\")\n",
    "        results_table.append({\"Kernel\": f\"Poly(deg={degree})\", \"C\": C, \"Degree\": degree,\n",
    "                               \"Val Acc\": round(val_acc, 4), \"Test Acc\": round(test_acc, 4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best polynomial configuration based on validation accuracy\n",
    "poly_results = [r for r in results_table if \"Poly\" in r[\"Kernel\"]]\n",
    "best_poly    = max(poly_results, key=lambda x: x[\"Val Acc\"])\n",
    "\n",
    "print(f\"Best Poly Config: Degree={best_poly['Degree']}, C={best_poly['C']}  \"\n",
    "      f\"(Val Acc: {best_poly['Val Acc']:.4f})\")\n",
    "\n",
    "# Training best poly model and printing detailed metrics\n",
    "best_poly_model = SVC(kernel='poly', degree=best_poly['Degree'], C=best_poly['C'], gamma='scale')\n",
    "best_poly_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print_metrics(y_val,  best_poly_model.predict(X_val_scaled),\n",
    "              dataset_name=f\"Poly SVM (deg={best_poly['Degree']}, C={best_poly['C']}) – Validation\")\n",
    "print_metrics(y_test, best_poly_model.predict(X_test_scaled),\n",
    "              dataset_name=f\"Poly SVM (deg={best_poly['Degree']}, C={best_poly['C']}) – Test\")\n",
    "\n",
    "# Weight vectors are NOT accessible for polynomial kernel\n",
    "print(\"\\nNote: Weight vectors are not available for Polynomial kernel.\")\n",
    "print(\"The decision boundary exists in a higher-dimensional space.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c7d8",
   "metadata": {},
   "source": [
    "### Task 2c: SVM with RBF Kernel\n",
    "\n",
    "RBF kernel: $K(x_i, x_j) = \\exp(-\\gamma \\|x_i - x_j\\|^2)$\n",
    "\n",
    "It measures similarity between points based on distance. Works well for most non-linear problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM with RBF Kernel – Tuning C\\n\")\n",
    "print(f\"{'C':<10} {'Val Accuracy':<18} {'Test Accuracy'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "best_val_acc_rbf = 0\n",
    "best_C_rbf       = None\n",
    "best_rbf_model   = None\n",
    "\n",
    "for C in C_values:\n",
    "    rbf_svm = SVC(kernel='rbf', C=C, gamma='scale')\n",
    "    rbf_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_val_pred  = rbf_svm.predict(X_val_scaled)\n",
    "    y_test_pred = rbf_svm.predict(X_test_scaled)\n",
    "\n",
    "    val_acc  = accuracy_score(y_val,  y_val_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"{C:<10} {val_acc:<18.4f} {test_acc:.4f}\")\n",
    "    results_table.append({\"Kernel\": \"RBF\", \"C\": C, \"Degree\": \"-\",\n",
    "                           \"Val Acc\": round(val_acc, 4), \"Test Acc\": round(test_acc, 4)})\n",
    "\n",
    "    if val_acc > best_val_acc_rbf:\n",
    "        best_val_acc_rbf = val_acc\n",
    "        best_C_rbf       = C\n",
    "        best_rbf_model   = rbf_svm\n",
    "\n",
    "print(f\"\\n>> Best C for RBF SVM: {best_C_rbf}  (Val Accuracy: {best_val_acc_rbf:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed metrics for best RBF SVM\n",
    "print_metrics(y_val,  best_rbf_model.predict(X_val_scaled),\n",
    "              dataset_name=f\"RBF SVM (C={best_C_rbf}) – Validation\")\n",
    "print_metrics(y_test, best_rbf_model.predict(X_test_scaled),\n",
    "              dataset_name=f\"RBF SVM (C={best_C_rbf}) – Test\")\n",
    "\n",
    "print(\"\\nNote: Weight vectors are not available for RBF kernel.\")\n",
    "print(\"The decision boundary exists in an infinite-dimensional space.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Complete Results Table\n",
    "\n",
    "Let's display all results in one table to compare across all kernels and C values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the collected results\n",
    "results_df = pd.DataFrame(results_table)\n",
    "\n",
    "# Displaying the full table\n",
    "print(\"COMPLETE RESULTS TABLE – All Kernels and C values\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV for future reference\n",
    "results_df.to_csv(\"svm_results_table.csv\", index=False)\n",
    "print(\"Results saved to 'svm_results_table.csv'\")\n",
    "\n",
    "# Quick summary: Best config per kernel\n",
    "print(\"\\n--- Best Configuration per Kernel (based on Val Accuracy) ---\")\n",
    "best_per_kernel = results_df.loc[results_df.groupby(\"Kernel\")[\"Val Acc\"].idxmax()]\n",
    "print(best_per_kernel.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Task | Model | Notes |\n",
    "|------|-------|-------|\n",
    "| Task 1 | Logistic Regression | Linear classifier, feature weights accessible via `coef_` |\n",
    "| Task 2a | SVM – Linear | Weight vector accessible, good baseline |\n",
    "| Task 2b | SVM – Polynomial | Non-linear, weights not accessible, tune degree + C |\n",
    "| Task 2c | SVM – RBF | Non-linear, weights not accessible, usually best performer |\n",
    "| Task 3 | Metrics | Confusion Matrix, Accuracy, Precision, Recall, F1 (Macro & Micro) |\n",
    "\n",
    "**Key takeaways:**\n",
    "- Always **scale your data** before training LR or SVM.\n",
    "- Use the **validation set** to tune C (not the test set!).\n",
    "- RBF kernel is usually a strong choice for non-linear data.\n",
    "- Weight vectors can only be interpreted for the **linear kernel**."
   ]
  }
 ]
}
