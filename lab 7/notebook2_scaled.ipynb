{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Logistic Regression and SVM\n",
    "## Notebook 2: Scaled Data\n",
    "### CS201L - Artificial Intelligence Laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score,\n",
    "    f1_score, classification_report\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Scaled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the standardized (scaled) train, validation and test data\n",
    "train_data = pd.read_csv('activity_scaled_train.csv')\n",
    "val_data   = pd.read_csv('activity_scaled_validation.csv')\n",
    "test_data  = pd.read_csv('activity_scaled_test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Validation shape:\", val_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating features and target labels\n",
    "X_train = train_data.drop(columns=['Activity'])\n",
    "y_train = train_data['Activity']\n",
    "\n",
    "X_val = val_data.drop(columns=['Activity'])\n",
    "y_val = val_data['Activity']\n",
    "\n",
    "X_test = test_data.drop(columns=['Activity'])\n",
    "y_test = test_data['Activity']\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\",   X_val.shape)\n",
    "print(\"X_test shape:\",  X_test.shape)\n",
    "print(\"\\nClasses:\", y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print all evaluation metrics nicely\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"Validation\"):\n",
    "    print(f\"\\n--- {dataset_name} Results ---\")\n",
    "    \n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec  = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1   = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=np.unique(y_true),\n",
    "                yticklabels=np.unique(y_true))\n",
    "    plt.title(f'Confusion Matrix - {dataset_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print(\"Helper function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Logistic Regression on scaled data...\")\n",
    "\n",
    "logistic_reg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training done!\")\n",
    "\n",
    "y_val_pred_lr  = logistic_reg.predict(X_val)\n",
    "y_test_pred_lr = logistic_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"TASK 2.1: LOGISTIC REGRESSION - SCALED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "acc_lr_val  = evaluate_model(y_val, y_val_pred_lr, \"Validation\")\n",
    "acc_lr_test = evaluate_model(y_test, y_test_pred_lr, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SVM with Linear Kernel on scaled data... (may take a few minutes)\")\n",
    "\n",
    "linear_svm = SVC(kernel='linear', C=1.0)\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "y_val_pred_lin  = linear_svm.predict(X_val)\n",
    "y_test_pred_lin = linear_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"TASK 2.2: SVM (LINEAR KERNEL) - SCALED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "acc_lin_val  = evaluate_model(y_val, y_val_pred_lin, \"Validation\")\n",
    "acc_lin_test = evaluate_model(y_test, y_test_pred_lin, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: SVM with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Polynomial SVM for degrees 2, 3, 4, 5 on scaled data...\")\n",
    "print(\"(Please wait, this takes a while)\\n\")\n",
    "\n",
    "best_degree  = None\n",
    "best_val_acc = 0\n",
    "degree_val_accuracies = {}\n",
    "\n",
    "for degree in [2, 3, 4, 5]:\n",
    "    poly_svm = SVC(kernel='poly', degree=degree, C=1.0, gamma='scale')\n",
    "    poly_svm.fit(X_train, y_train)\n",
    "    \n",
    "    val_acc = poly_svm.score(X_val, y_val)\n",
    "    degree_val_accuracies[degree] = val_acc\n",
    "    print(f\"Degree={degree}, Validation Accuracy={val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_degree  = degree\n",
    "\n",
    "print(f\"\\nBest Degree: {best_degree} with Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(list(degree_val_accuracies.keys()), list(degree_val_accuracies.values()), marker='o', color='orange')\n",
    "plt.title('Polynomial SVM: Validation Accuracy vs Degree (Scaled Data)')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xticks([2, 3, 4, 5])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training final Polynomial SVM with best degree = {best_degree}...\")\n",
    "\n",
    "best_poly_svm = SVC(kernel='poly', degree=best_degree, C=1.0, gamma='scale')\n",
    "best_poly_svm.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_poly  = best_poly_svm.predict(X_val)\n",
    "y_test_pred_poly = best_poly_svm.predict(X_test)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(f\"TASK 2.3: SVM (POLY KERNEL, DEGREE={best_degree}) - SCALED DATA\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\nValidation Accuracies for all degrees:\")\n",
    "for d, acc in degree_val_accuracies.items():\n",
    "    marker = \" <-- best\" if d == best_degree else \"\"\n",
    "    print(f\"  Degree {d}: {acc:.4f}{marker}\")\n",
    "\n",
    "acc_poly_val  = evaluate_model(y_val, y_val_pred_poly, \"Validation (Best Degree)\")\n",
    "acc_poly_test = evaluate_model(y_test, y_test_pred_poly, \"Test (Best Degree)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: SVM with Gaussian (RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SVM with RBF Kernel on scaled data...\")\n",
    "\n",
    "rbf_svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "rbf_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "y_val_pred_rbf  = rbf_svm.predict(X_val)\n",
    "y_test_pred_rbf = rbf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"TASK 2.4: SVM (RBF KERNEL) - SCALED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "acc_rbf_val  = evaluate_model(y_val, y_val_pred_rbf, \"Validation\")\n",
    "acc_rbf_test = evaluate_model(y_test, y_test_pred_rbf, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5: Comparison on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_val = {\n",
    "    'Classifier':          ['Logistic Regression', 'SVM Linear', f'SVM Poly (d={best_degree})', 'SVM RBF'],\n",
    "    'Validation Accuracy': [acc_lr_val, acc_lin_val, acc_poly_val, acc_rbf_val]\n",
    "}\n",
    "\n",
    "comparison_test = {\n",
    "    'Classifier':    ['Logistic Regression', 'SVM Linear', f'SVM Poly (d={best_degree})', 'SVM RBF'],\n",
    "    'Test Accuracy': [acc_lr_test, acc_lin_test, acc_poly_test, acc_rbf_test]\n",
    "}\n",
    "\n",
    "df_val  = pd.DataFrame(comparison_val)\n",
    "df_test = pd.DataFrame(comparison_test)\n",
    "\n",
    "print(\"Validation Accuracy Comparison (Scaled Data):\")\n",
    "print(df_val.to_string(index=False))\n",
    "\n",
    "print(\"\\nTest Accuracy Comparison (Scaled Data):\")\n",
    "print(df_test.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Logistic\\nRegression', 'SVM\\nLinear', f'SVM Poly\\n(d={best_degree})', 'SVM\\nRBF']\n",
    "val_accs  = [acc_lr_val, acc_lin_val, acc_poly_val, acc_rbf_val]\n",
    "test_accs = [acc_lr_test, acc_lin_test, acc_poly_test, acc_rbf_test]\n",
    "\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "bars1 = ax.bar(x - width/2, val_accs,  width, label='Validation')\n",
    "bars2 = ax.bar(x + width/2, test_accs, width, label='Test')\n",
    "\n",
    "ax.set_title('Classifier Accuracy Comparison - Scaled Data')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classifiers)\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "\n",
    "for bar in bars1:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_val_clf  = classifiers[np.argmax(val_accs)].replace('\\n', ' ')\n",
    "best_test_clf = classifiers[np.argmax(test_accs)].replace('\\n', ' ')\n",
    "print(f\"\\nDiscussion:\")\n",
    "print(f\"Best classifier on Validation: {best_val_clf} ({max(val_accs):.4f})\")\n",
    "print(f\"Best classifier on Test:       {best_test_clf} ({max(test_accs):.4f})\")\n",
    "print(\"Scaling the data often helps SVMs perform better, especially RBF kernel,\")\n",
    "print(\"because it makes the features comparable and the kernel distances more meaningful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy values to record for final comparison (Notebook 4):\")\n",
    "print(f\"  LR  Val: {acc_lr_val:.4f}   | LR  Test: {acc_lr_test:.4f}\")\n",
    "print(f\"  Lin Val: {acc_lin_val:.4f}   | Lin Test: {acc_lin_test:.4f}\")\n",
    "print(f\"  Poly Val: {acc_poly_val:.4f} | Poly Test: {acc_poly_test:.4f}\")\n",
    "print(f\"  RBF Val: {acc_rbf_val:.4f}   | RBF Test: {acc_rbf_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
