{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Logistic Regression and SVM\n",
    "## Notebook 4: PCA Transformed Data (99% Variance) + Overall Comparison\n",
    "### CS201L - Artificial Intelligence Laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score,\n",
    "    f1_score, classification_report\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the PCA (99% Variance) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pca 99% variance data\n",
    "# this dataset only keeps enough components to explain 99% of the variance\n",
    "# so we expect fewer features than the original 561\n",
    "train_data = pd.read_csv('activity_pca99_train.csv')\n",
    "val_data   = pd.read_csv('activity_pca99_validation.csv')\n",
    "test_data  = pd.read_csv('activity_pca99_test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Validation shape:\", val_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['Activity'])\n",
    "y_train = train_data['Activity']\n",
    "\n",
    "X_val = val_data.drop(columns=['Activity'])\n",
    "y_val = val_data['Activity']\n",
    "\n",
    "X_test = test_data.drop(columns=['Activity'])\n",
    "y_test = test_data['Activity']\n",
    "\n",
    "print(f\"Number of PCA components (99% variance): {X_train.shape[1]}\")\n",
    "print(\"Classes:\", y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, dataset_name=\"Validation\"):\n",
    "    print(f\"\\n--- {dataset_name} Results ---\")\n",
    "    \n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec  = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1   = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
    "                xticklabels=np.unique(y_true),\n",
    "                yticklabels=np.unique(y_true))\n",
    "    plt.title(f'Confusion Matrix - {dataset_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print(\"Helper function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Logistic Regression on PCA 99% variance data...\")\n",
    "\n",
    "logistic_reg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "y_val_pred_lr  = logistic_reg.predict(X_val)\n",
    "y_test_pred_lr = logistic_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"TASK 4.1: LOGISTIC REGRESSION - PCA 99% VARIANCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "acc_lr_val  = evaluate_model(y_val, y_val_pred_lr, \"Validation\")\n",
    "acc_lr_test = evaluate_model(y_test, y_test_pred_lr, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2: SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SVM Linear on PCA 99% variance data... (may take a few minutes)\")\n",
    "\n",
    "linear_svm = SVC(kernel='linear', C=1.0)\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "y_val_pred_lin  = linear_svm.predict(X_val)\n",
    "y_test_pred_lin = linear_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"TASK 4.2: SVM (LINEAR KERNEL) - PCA 99% VARIANCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "acc_lin_val  = evaluate_model(y_val, y_val_pred_lin, \"Validation\")\n",
    "acc_lin_test = evaluate_model(y_test, y_test_pred_lin, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3: SVM with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Polynomial SVM for degrees 2, 3, 4, 5 on PCA 99% variance data...\")\n",
    "print(\"(Please wait)\\n\")\n",
    "\n",
    "best_degree  = None\n",
    "best_val_acc = 0\n",
    "degree_val_accuracies = {}\n",
    "\n",
    "for degree in [2, 3, 4, 5]:\n",
    "    poly_svm = SVC(kernel='poly', degree=degree, C=1.0, gamma='scale')\n",
    "    poly_svm.fit(X_train, y_train)\n",
    "    \n",
    "    val_acc = poly_svm.score(X_val, y_val)\n",
    "    degree_val_accuracies[degree] = val_acc\n",
    "    print(f\"Degree={degree}, Validation Accuracy={val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_degree  = degree\n",
    "\n",
    "print(f\"\\nBest Degree: {best_degree} with Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(list(degree_val_accuracies.keys()), list(degree_val_accuracies.values()), marker='D', color='purple')\n",
    "plt.title('Polynomial SVM: Validation Accuracy vs Degree (PCA 99%)')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xticks([2, 3, 4, 5])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training final model with best degree = {best_degree}...\")\n",
    "\n",
    "best_poly_svm = SVC(kernel='poly', degree=best_degree, C=1.0, gamma='scale')\n",
    "best_poly_svm.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_poly  = best_poly_svm.predict(X_val)\n",
    "y_test_pred_poly = best_poly_svm.predict(X_test)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(f\"TASK 4.3: SVM (POLY KERNEL, DEGREE={best_degree}) - PCA 99% VARIANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nValidation Accuracies for all degrees:\")\n",
    "for d, acc in degree_val_accuracies.items():\n",
    "    marker = \" <-- best\" if d == best_degree else \"\"\n",
    "    print(f\"  Degree {d}: {acc:.4f}{marker}\")\n",
    "\n",
    "acc_poly_val  = evaluate_model(y_val, y_val_pred_poly, \"Validation (Best Degree)\")\n",
    "acc_poly_test = evaluate_model(y_test, y_test_pred_poly, \"Test (Best Degree)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.4: SVM with Gaussian (RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SVM with RBF Kernel on PCA 99% variance data...\")\n",
    "\n",
    "rbf_svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "rbf_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "y_val_pred_rbf  = rbf_svm.predict(X_val)\n",
    "y_test_pred_rbf = rbf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"TASK 4.4: SVM (RBF KERNEL) - PCA 99% VARIANCE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "acc_rbf_val  = evaluate_model(y_val, y_val_pred_rbf, \"Validation\")\n",
    "acc_rbf_test = evaluate_model(y_test, y_test_pred_rbf, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.5: Comparison on PCA 99% Variance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_val = {\n",
    "    'Classifier':          ['Logistic Regression', 'SVM Linear', f'SVM Poly (d={best_degree})', 'SVM RBF'],\n",
    "    'Validation Accuracy': [acc_lr_val, acc_lin_val, acc_poly_val, acc_rbf_val]\n",
    "}\n",
    "\n",
    "comparison_test = {\n",
    "    'Classifier':    ['Logistic Regression', 'SVM Linear', f'SVM Poly (d={best_degree})', 'SVM RBF'],\n",
    "    'Test Accuracy': [acc_lr_test, acc_lin_test, acc_poly_test, acc_rbf_test]\n",
    "}\n",
    "\n",
    "df_val  = pd.DataFrame(comparison_val)\n",
    "df_test = pd.DataFrame(comparison_test)\n",
    "\n",
    "print(\"Validation Accuracy Comparison (PCA 99% Variance):\")\n",
    "print(df_val.to_string(index=False))\n",
    "\n",
    "print(\"\\nTest Accuracy Comparison (PCA 99% Variance):\")\n",
    "print(df_test.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Logistic\\nRegression', 'SVM\\nLinear', f'SVM Poly\\n(d={best_degree})', 'SVM\\nRBF']\n",
    "val_accs  = [acc_lr_val, acc_lin_val, acc_poly_val, acc_rbf_val]\n",
    "test_accs = [acc_lr_test, acc_lin_test, acc_poly_test, acc_rbf_test]\n",
    "\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "bars1 = ax.bar(x - width/2, val_accs,  width, label='Validation', color='mediumpurple')\n",
    "bars2 = ax.bar(x + width/2, test_accs, width, label='Test', color='plum')\n",
    "\n",
    "ax.set_title('Classifier Accuracy Comparison - PCA 99% Variance')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classifiers)\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "\n",
    "for bar in bars1:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_val_clf  = classifiers[np.argmax(val_accs)].replace('\\n', ' ')\n",
    "best_test_clf = classifiers[np.argmax(test_accs)].replace('\\n', ' ')\n",
    "print(f\"\\nDiscussion:\")\n",
    "print(f\"Best classifier on Validation: {best_val_clf} ({max(val_accs):.4f})\")\n",
    "print(f\"Best classifier on Test:       {best_test_clf} ({max(test_accs):.4f})\")\n",
    "print(\"PCA with 99% variance reduces dimensionality slightly while preserving most information.\")\n",
    "print(\"Training should be slightly faster than full PCA or original data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4.5 (Overall): Cross-Dataset Comparison\n",
    "\n",
    "**Note:** Before running this section, manually copy the accuracy values from Notebooks 1, 2, and 3 into the variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTANT: Fill in values from the other notebooks below!\n",
    "# You can find these printed at the bottom of each notebook.\n",
    "# ============================================================\n",
    "\n",
    "# --- Notebook 1: Original Data ---\n",
    "acc_lr_orig_val    = 0.0  # replace with actual value from Notebook 1\n",
    "acc_lin_orig_val   = 0.0\n",
    "acc_poly_orig_val  = 0.0\n",
    "acc_rbf_orig_val   = 0.0\n",
    "\n",
    "acc_lr_orig_test   = 0.0\n",
    "acc_lin_orig_test  = 0.0\n",
    "acc_poly_orig_test = 0.0\n",
    "acc_rbf_orig_test  = 0.0\n",
    "\n",
    "# --- Notebook 2: Scaled Data ---\n",
    "acc_lr_scaled_val    = 0.0  # replace with actual value from Notebook 2\n",
    "acc_lin_scaled_val   = 0.0\n",
    "acc_poly_scaled_val  = 0.0\n",
    "acc_rbf_scaled_val   = 0.0\n",
    "\n",
    "acc_lr_scaled_test   = 0.0\n",
    "acc_lin_scaled_test  = 0.0\n",
    "acc_poly_scaled_test = 0.0\n",
    "acc_rbf_scaled_test  = 0.0\n",
    "\n",
    "# --- Notebook 3: PCA All Components ---\n",
    "acc_lr_pcaall_val    = 0.0  # replace with actual value from Notebook 3\n",
    "acc_lin_pcaall_val   = 0.0\n",
    "acc_poly_pcaall_val  = 0.0\n",
    "acc_rbf_pcaall_val   = 0.0\n",
    "\n",
    "acc_lr_pcaall_test   = 0.0\n",
    "acc_lin_pcaall_test  = 0.0\n",
    "acc_poly_pcaall_test = 0.0\n",
    "acc_rbf_pcaall_test  = 0.0\n",
    "\n",
    "# --- This Notebook (Notebook 4): PCA 99% Variance ---\n",
    "# These are already computed above - no need to change these\n",
    "acc_lr_pca99_val    = acc_lr_val\n",
    "acc_lin_pca99_val   = acc_lin_val\n",
    "acc_poly_pca99_val  = acc_poly_val\n",
    "acc_rbf_pca99_val   = acc_rbf_val\n",
    "\n",
    "acc_lr_pca99_test   = acc_lr_test\n",
    "acc_lin_pca99_test  = acc_lin_test\n",
    "acc_poly_pca99_test = acc_poly_test\n",
    "acc_rbf_pca99_test  = acc_rbf_test\n",
    "\n",
    "print(\"Values loaded! Remember to replace the 0.0 placeholders with actual values from other notebooks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Validation Accuracy Comparison Table\n",
    "data_val = {\n",
    "    \"Dataset\":            [\"Original\", \"Scaled\", \"PCA All\", \"PCA 99\"],\n",
    "    \"Logistic Regression\": [acc_lr_orig_val,   acc_lr_scaled_val,   acc_lr_pcaall_val,   acc_lr_pca99_val],\n",
    "    \"SVM Linear\":          [acc_lin_orig_val,  acc_lin_scaled_val,  acc_lin_pcaall_val,  acc_lin_pca99_val],\n",
    "    \"SVM Polynomial\":      [acc_poly_orig_val, acc_poly_scaled_val, acc_poly_pcaall_val, acc_poly_pca99_val],\n",
    "    \"SVM Gaussian\":        [acc_rbf_orig_val,  acc_rbf_scaled_val,  acc_rbf_pcaall_val,  acc_rbf_pca99_val]\n",
    "}\n",
    "\n",
    "df_overall_val = pd.DataFrame(data_val)\n",
    "df_overall_val.set_index(\"Dataset\", inplace=True)\n",
    "\n",
    "print(\"Validation Accuracy Comparison (All Datasets)\")\n",
    "print(df_overall_val.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Test Accuracy Comparison Table\n",
    "data_test = {\n",
    "    \"Dataset\":            [\"Original\", \"Scaled\", \"PCA All\", \"PCA 99\"],\n",
    "    \"Logistic Regression\": [acc_lr_orig_test,   acc_lr_scaled_test,   acc_lr_pcaall_test,   acc_lr_pca99_test],\n",
    "    \"SVM Linear\":          [acc_lin_orig_test,  acc_lin_scaled_test,  acc_lin_pcaall_test,  acc_lin_pca99_test],\n",
    "    \"SVM Polynomial\":      [acc_poly_orig_test, acc_poly_scaled_test, acc_poly_pcaall_test, acc_poly_pca99_test],\n",
    "    \"SVM Gaussian\":        [acc_rbf_orig_test,  acc_rbf_scaled_test,  acc_rbf_pcaall_test,  acc_rbf_pca99_test]\n",
    "}\n",
    "\n",
    "df_overall_test = pd.DataFrame(data_test)\n",
    "df_overall_test.set_index(\"Dataset\", inplace=True)\n",
    "\n",
    "print(\"Test Accuracy Comparison (All Datasets)\")\n",
    "print(df_overall_test.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of validation accuracies across datasets and classifiers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "sns.heatmap(df_overall_val, annot=True, fmt='.4f', cmap='YlGnBu',\n",
    "            ax=axes[0], vmin=0.5, vmax=1.0)\n",
    "axes[0].set_title('Validation Accuracy Across Datasets & Classifiers')\n",
    "axes[0].set_ylabel('Dataset')\n",
    "\n",
    "sns.heatmap(df_overall_test, annot=True, fmt='.4f', cmap='YlOrRd',\n",
    "            ax=axes[1], vmin=0.5, vmax=1.0)\n",
    "axes[1].set_title('Test Accuracy Across Datasets & Classifiers')\n",
    "axes[1].set_ylabel('Dataset')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot to see trends across datasets for each classifier\n",
    "datasets   = ['Original', 'Scaled', 'PCA All', 'PCA 99%']\n",
    "lr_vals    = [acc_lr_orig_test,   acc_lr_scaled_test,   acc_lr_pcaall_test,   acc_lr_pca99_test]\n",
    "lin_vals   = [acc_lin_orig_test,  acc_lin_scaled_test,  acc_lin_pcaall_test,  acc_lin_pca99_test]\n",
    "poly_vals  = [acc_poly_orig_test, acc_poly_scaled_test, acc_poly_pcaall_test, acc_poly_pca99_test]\n",
    "rbf_vals   = [acc_rbf_orig_test,  acc_rbf_scaled_test,  acc_rbf_pcaall_test,  acc_rbf_pca99_test]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(datasets, lr_vals,   marker='o', label='Logistic Regression')\n",
    "plt.plot(datasets, lin_vals,  marker='s', label='SVM Linear')\n",
    "plt.plot(datasets, poly_vals, marker='^', label='SVM Polynomial')\n",
    "plt.plot(datasets, rbf_vals,  marker='D', label='SVM RBF')\n",
    "\n",
    "plt.title('Test Accuracy of Classifiers Across Different Datasets')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Dataset')\n",
    "plt.legend()\n",
    "plt.ylim(0.5, 1.05)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final overall discussion\n",
    "print(\"=\"*65)\n",
    "print(\"OVERALL DISCUSSION - CROSS-DATASET COMPARISON\")\n",
    "print(\"=\"*65)\n",
    "print(\"\"\"\n",
    "Key Observations:\n",
    "\n",
    "1. Feature Scaling:\n",
    "   - SVMs (especially RBF and Linear) generally perform better on scaled data\n",
    "     because scaling ensures all features contribute equally to the kernel \n",
    "     distance computation.\n",
    "   - Logistic Regression also benefits from scaling for faster convergence.\n",
    "\n",
    "2. PCA All Components:\n",
    "   - When PCA is applied with all components, the data is rotated to the \n",
    "     principal component space. Performance is similar to scaled data since\n",
    "     no variance is discarded.\n",
    "\n",
    "3. PCA 99% Variance:\n",
    "   - By keeping only enough components for 99% variance, we reduce\n",
    "     dimensionality slightly while preserving most of the information.\n",
    "   - This can make training a bit faster without losing much accuracy.\n",
    "\n",
    "4. Best Overall Classifier:\n",
    "   - SVM with RBF kernel generally performs best on scaled/PCA data.\n",
    "   - SVM with Linear kernel also performs very well on this dataset.\n",
    "   - Logistic Regression is competitive and much faster to train.\n",
    "   - Polynomial SVM is the most sensitive to the degree chosen and is \n",
    "     generally slower to train.\n",
    "\n",
    "Conclusion:\n",
    "   For the HAR dataset, SVM with RBF kernel on scaled or PCA-transformed \n",
    "   data tends to give the best results. However, if speed is a concern, \n",
    "   Logistic Regression is a strong and efficient baseline.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
